//
//  UploadAudioController.swift
//  Mobiusi_iOS
//
//  Created by MY on 2025/10/30.
//

import SwiftUI
import Foundation
import AVFoundation
import CryptoKit

struct UploadAudioController:View {
    @Environment(\.dismiss) private var dismiss
    let dataItem: IndexItem?

    init(dataItem: IndexItem? = nil) {
        self.dataItem = dataItem
    }

    @State private var recordTime: Int = 0 //ç§’æ•°
    @State private var isRecorded: Bool = false //æ˜¯å¦å½•åˆ¶å®Œæˆ
    @State private var audioURL: String = "" //éŸ³é¢‘url
    @State private var isPlaying: Bool = false //æ˜¯å¦æ­£åœ¨æ’­æ”¾
    @State private var isRecording: Bool = false //æ˜¯å¦æ­£åœ¨å½•åˆ¶
    @State private var duration: Int = 0 //éŸ³é¢‘æ—¶é•¿
    @State private var path: String = "" //éŸ³é¢‘è·¯å¾„
    @State private var navigateToReleasePanel: Bool = false // ä¸Šä¼ æˆåŠŸåå¯¼èˆªè§¦å‘
     // å½•éŸ³æƒé™è®¾ç½®æç¤ºå¯¹è¯æ¡†çŠ¶æ€
    @State private var showRecordingPermissionSettingsDialog: Bool = false
     // å½•éŸ³æƒé™çŠ¶æ€
    @State private var recordingPermissionStatus: AVAudioSession.RecordPermission = .undetermined
    
    // éŸ³é¢‘å½•åˆ¶ç›¸å…³
    @State private var audioRecorder: AVAudioRecorder?
    @State private var recordingTimer: Timer?
    @State private var audioSession: AVAudioSession = AVAudioSession.sharedInstance()
    
    var body: some View {
       ZStack{
           // çºµå‘æ¸å˜èƒŒæ™¯
           LinearGradient(
               gradient: Gradient(stops: [
                   .init(color: Color(hex: "#FFACB7"), location: 0.0),   // ç²‰è‰²ä»é¡¶éƒ¨å¼€å§‹
                   .init(color: Color(hex: "#FFACB7"), location: 0.3),   // ç²‰è‰²å 30%
                   .init(color: Color(hex: "#EDEEF5"), location: 0.5),   // ä»70%å¼€å§‹è¿‡æ¸¡åˆ°ç°è‰²
                   .init(color: Color(hex: "#EDEEF5"), location: 1.0)    // ç°è‰²åˆ°åº•éƒ¨
               ]),
               startPoint: .top,
               endPoint: .bottom
           )
           .ignoresSafeArea()
           VStack(spacing:30){
            HStack{
                Button(action:{
                    dismiss()
                }){
                      Text("å–æ¶ˆ")
                    .font(.system(size: 14))
                    .foregroundColor(.black)
                }
                .contentShape(Rectangle())
              
                    Spacer()
              //å½•åˆ¶å®ŒéŸ³é¢‘æ‰æ˜¾ç¤º
                if isRecorded{
                    Button(action:{
                         if duration >= 5 {
                              getPreSignedURL()
                            
                            }else{
                                MBProgressHUD.showMessag("å½•éŸ³æ—¶é•¿ä¸èƒ½ä½äº5s", to: nil, afterDelay: 3.0)
                            }
                    }){
                         Text("ä¸‹ä¸€æ­¥")
                        .font(.system(size: 14))
                        .foregroundColor(.white)
                        .padding(.vertical, 8)
                        .padding(.horizontal, 16)
                        .background(Color(hex: "#9A1E2E"))
                        .cornerRadius(12)
                        
                    }
                    .contentShape(Rectangle())
                   
                
            }
            }
              .padding(.horizontal,25)
            Image("icon_free_record")
             .resizable()
             .scaledToFit()
             .frame(maxWidth: .infinity)
               .padding(.horizontal,25)
            HStack{
                Spacer()
                 VStack(alignment:.center,spacing:10){
                    Text("\(recordTime)s")
                        .font(.system(size: 14))
                        .foregroundColor(.black)
                    Text("å½•éŸ³æ—¶é•¿ä¸èƒ½ä½äº5s")
                        .font(.system(size: 16))
                        .foregroundColor(Color(hex:"#9B9B9B"))
                 }
                Spacer()
            }
            Spacer()
            //å½•åˆ¶å®Œæˆçš„æ¨¡å—
            if isRecorded{
                VStack(alignment:.leading,spacing:20){
                    Text("å½•åˆ¶å®Œæˆï¼Œå¯ç‚¹å‡»è¯•å¬")
                        .font(.system(size: 16))
                        .foregroundColor(Color(hex:"#9B9B9B"))
                          .padding(.horizontal,25)
                     AudioSpectrogram(audioURL: audioURL)
                       .padding(.horizontal,25)
                     HStack{
                        Text("é‡æ–°å½•åˆ¶")
                            .font(.system(size: 18))
                            .foregroundColor(Color(hex:"#9A1E2E"))
                            .padding(.vertical,18)
                            .frame(width: UIScreen.main.bounds.width/2.4)
                            .background(Color(hex:"#9A1E2E").opacity(0.2))
                            .cornerRadius(12)
                            .onTapGesture {
                                resetRecording()
                            }
                            Spacer()
                            Button(action:{
                                if duration >= 5 {
                              getPreSignedURL()
                            
                            }else{
                                MBProgressHUD.showMessag("å½•éŸ³æ—¶é•¿ä¸èƒ½ä½äº5s", to: nil, afterDelay: 3.0)
                            }
                            }){
                             Text("ä¸‹ä¸€æ­¥")
                            .font(.system(size: 18))
                            .foregroundColor(Color(hex:"#ffffff"))
                            .padding(.vertical,18)
                            .frame(width: UIScreen.main.bounds.width/2.4)
                            .background(Color(hex:"#9A1E2E"))
                            .cornerRadius(12)
                          }
                          // éšè—çš„å¯¼èˆªé“¾æ¥ï¼šä¸Šä¼ æˆåŠŸåè·³è½¬åˆ°å‘å¸ƒé¢æ¿
                          NavigationLink(
                              destination: AudioReleasePanel(audioURL: audioURL, duration: duration, path: path, dataItem: dataItem)
                                  .toolbar(.hidden, for: .navigationBar)
                                  .toolbarColorScheme(.dark),
                              isActive: $navigateToReleasePanel
                          ) {
                              EmptyView()
                          }
                          .hidden()
                     }
                     .padding(.vertical,15)
                     .padding(.horizontal,20)
                     .frame(width: .infinity)
                     .background(Color.white)
                  
                }
            }else{
                VStack(alignment:.center,spacing:20){
                   Image(isRecording ? "icon_record_micing" : "icon_record_mic")
                        .resizable()
                        .scaledToFit()
                        .frame(width: 67, height:  67 )
                        .onTapGesture{
                            handleRecordButtonTap()
                        }
                   Text(isRecording ? "å†æ¬¡ç‚¹å‡»åœæ­¢å½•åˆ¶" : "ç‚¹å‡»å½•åˆ¶")
                        .font(.system(size: 14))
                        .foregroundColor(Color(hex:"#9B9B9B"))

                }
                .padding(.bottom,20)
            
           }
          
           
       }
         .padding(.vertical,10)
       
         // å½•éŸ³æƒé™è®¾ç½®æç¤ºå¯¹è¯æ¡†è¦†ç›–å±‚ - åªåœ¨æƒé™è¢«æ‹’ç»æ—¶æ˜¾ç¤º
            if showRecordingPermissionSettingsDialog && recordingPermissionStatus == .denied {
                recordingPermissionSettingsDialogOverlay
                    .zIndex(1200)
            }
      
      
     }
     .navigationBarHidden(true)
     .toolbar(.hidden, for: .navigationBar)
       .ignoresSafeArea(edges: .bottom)
      .navigationBarBackButtonHidden(true)
      .onAppear {
          setupAudioSession()
          // æ£€æŸ¥å½“å‰å½•éŸ³æƒé™çŠ¶æ€
          checkRecordingPermission()
      }
      .onDisappear {
          stopRecording()
      }
   }
   
   // MARK: - éŸ³é¢‘å½•åˆ¶ç›¸å…³æ–¹æ³•
   
   /// è®¾ç½®éŸ³é¢‘ä¼šè¯ï¼ˆå¯¹é½ TaskDetailControllerï¼‰
   private func setupAudioSession() {
       do {
           // ä¸ TaskDetailController ä¿æŒä¸€è‡´ï¼šé»˜è®¤æ¨¡å¼ + å¤–æ”¾
           try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker])
           try audioSession.setActive(true)
       } catch {
           print("éŸ³é¢‘ä¼šè¯è®¾ç½®å¤±è´¥: \(error)")
       }
   }
   
   /// åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨ï¼ˆå¯¹é½ TaskDetailControllerï¼‰
   private func setupAudioRecorder() {
       let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
       let audioFilename = documentsPath.appendingPathComponent("recording_\(Date().timeIntervalSince1970).m4a")
       
       let settings: [String: Any] = [
           AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
           AVSampleRateKey: 44100,
           AVNumberOfChannelsKey: 2,
           AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
       ]
       
       do {
           audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
           audioRecorder?.delegate = nil
           
           // å¯ç”¨éŸ³é¢‘è®¡é‡ä»¥ç›‘æ§å½•åˆ¶è´¨é‡
           audioRecorder?.isMeteringEnabled = true
           
           // é¢„å‡†å¤‡å½•åˆ¶å™¨
           audioRecorder?.prepareToRecord()
           audioURL = audioFilename.absoluteString
       } catch {
           print("éŸ³é¢‘å½•åˆ¶å™¨åˆå§‹åŒ–å¤±è´¥: \(error)")
       }
   }

     /// æ£€æŸ¥å½“å‰å½•éŸ³æƒé™çŠ¶æ€
    private func checkRecordingPermission() {
        let currentStatus = AVAudioSession.sharedInstance().recordPermission
        recordingPermissionStatus = currentStatus
        
        // åªæœ‰åœ¨æƒé™è¢«æ‹’ç»æ—¶æ‰è¯·æ±‚æƒé™ï¼Œå¦‚æœå·²æˆæƒåˆ™ä¸åšä»»ä½•æ“ä½œ
        if currentStatus == .denied {
            requestRecordingPermission()
        } else if currentStatus == .granted {
            print("âœ… å½•éŸ³æƒé™å·²æˆæƒï¼Œæ— éœ€æ˜¾ç¤ºå¯¹è¯æ¡†")
            // æƒé™å·²æˆæƒï¼Œç¡®ä¿å¯¹è¯æ¡†è¢«éšè—
            showRecordingPermissionSettingsDialog = false
              
            
        }
    }

     /// è¯·æ±‚å½•éŸ³æƒé™
    private func requestRecordingPermission() {
        AVAudioSession.sharedInstance().requestRecordPermission { granted in
            DispatchQueue.main.async {
                self.recordingPermissionStatus = granted ? .granted : .denied
                
                if granted {
                    print("âœ… å½•éŸ³æƒé™å·²æˆæƒ")
                    // æƒé™æˆæƒæˆåŠŸï¼Œéšè—æ‰€æœ‰å½•éŸ³æƒé™ç›¸å…³å¯¹è¯æ¡†
                   
                    self.showRecordingPermissionSettingsDialog = false
                   
                } else {
                    print("âŒ å½•éŸ³æƒé™è¢«æ‹’ç»")
                    // æƒé™è¢«æ‹’ç»ï¼Œæ˜¾ç¤ºè®¾ç½®æç¤ºå¯¹è¯æ¡†
                    self.showRecordingPermissionSettingsDialog = true
                }
            }
        }
    }

     // MARK: - å½•éŸ³æƒé™è®¾ç½®æç¤ºå¯¹è¯æ¡†
    private var recordingPermissionSettingsDialogOverlay: some View {
        ZStack {
            Color.black.opacity(0.4)
                .ignoresSafeArea()
                .onTapGesture {
                    showRecordingPermissionSettingsDialog = false
                }

            VStack(spacing: 16) {
                Text("å½•éŸ³æƒé™è¢«æ‹’ç»")
                    .font(.system(size: 24, weight: .bold))
                    .foregroundColor(.black)
                    .multilineTextAlignment(.center)

                Text("ä¸ºäº†ä½¿ç”¨å½•éŸ³åŠŸèƒ½ï¼Œæ‚¨éœ€è¦åœ¨ç³»ç»Ÿè®¾ç½®ä¸­ä¸ºæœ¬åº”ç”¨å¼€å¯å½•éŸ³æƒé™ã€‚è¯·ç‚¹å‡»\"å‰å¾€è®¾ç½®\"æŒ‰é’®è·³è½¬åˆ°ç³»ç»Ÿè®¾ç½®é¡µé¢ã€‚")
                    .font(.system(size: 16))
                    .foregroundColor(Color.gray)
                    .multilineTextAlignment(.center)
                    .lineSpacing(8)

                HStack(spacing: 12) {
                    Button(action: {
                        showRecordingPermissionSettingsDialog = false
                    }) {
                        Text("å–æ¶ˆ")
                            .frame(maxWidth: .infinity)
                            .padding(.vertical, 10)
                    }
                    .background(Color(hex: "#EDEEF4"))
                    .foregroundColor(Color(hex: "#9B1E2E"))
                    .cornerRadius(10)

                    Button(action: {
                        showRecordingPermissionSettingsDialog = false
                        openAppSettings()
                    }) {
                        Text("å‰å¾€è®¾ç½®")
                            .frame(maxWidth: .infinity)
                            .padding(.vertical, 10)
                    }
                    .background(Color(hex: "#9B1E2E"))
                    .foregroundColor(.white)
                    .cornerRadius(10)
                }
            }
            .padding(20)
            .background(Color.white)
            .cornerRadius(12)
            .frame(maxWidth: 320)
        }
    }

     // è·³è½¬åˆ°ç³»ç»Ÿè®¾ç½®ä¸­çš„åº”ç”¨æƒé™ç®¡ç†é¡µé¢
    private func openAppSettings() {
        guard let settingsUrl = URL(string: UIApplication.openSettingsURLString) else {
            return
        }
        
        if UIApplication.shared.canOpenURL(settingsUrl) {
            UIApplication.shared.open(settingsUrl) { success in
                DispatchQueue.main.async {
                    if success {
                        print("æˆåŠŸè·³è½¬åˆ°ç³»ç»Ÿè®¾ç½®")
                    } else {
                        print("è·³è½¬åˆ°ç³»ç»Ÿè®¾ç½®å¤±è´¥")
                    }
                }
            }
        }
    }
   
   // å¼€å§‹å½•åˆ¶
   private func startRecording() {
       // ç¡®ä¿éŸ³é¢‘ä¼šè¯å¤„äºæ´»åŠ¨çŠ¶æ€
       do {
           try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP])
           try audioSession.setActive(true)
       } catch {
           print("æ¿€æ´»éŸ³é¢‘ä¼šè¯å¤±è´¥: \(error)")
           MBProgressHUD.showMessag("æ— æ³•å¯åŠ¨å½•éŸ³ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®", to: nil, afterDelay: 2.0)
           return
       }
       
       // åˆå§‹åŒ–å½•éŸ³å™¨
       setupAudioRecorder()
       
       guard let recorder = audioRecorder else {
           print("âŒ å½•éŸ³å™¨åˆå§‹åŒ–å¤±è´¥")
           MBProgressHUD.showMessag("å½•éŸ³å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•", to: nil, afterDelay: 2.0)
           return
       }
       
       // é‡ç½®çŠ¶æ€
       isRecording = true
       recordTime = 0
       isRecorded = false
       duration = 0
       
       // å¼€å§‹å½•åˆ¶
       let success = recorder.record()
       if success {
           print("âœ… å¼€å§‹å½•åˆ¶: \(audioURL)")
           
           // å¯åŠ¨è®¡æ—¶å™¨
           recordingTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { _ in
               DispatchQueue.main.async {
                   recordTime += 1
               }
           }
       } else {
           print("âŒ å½•åˆ¶å¯åŠ¨å¤±è´¥")
           isRecording = false
           MBProgressHUD.showMessag("å½•åˆ¶å¯åŠ¨å¤±è´¥ï¼Œè¯·é‡è¯•", to: nil, afterDelay: 2.0)
       }
   }
   
   /// åœæ­¢å½•åˆ¶
   private func stopRecording() {
       guard let recorder = audioRecorder else { return }
       
       isRecording = false
       recorder.stop()
       
       // åœæ­¢è®¡æ—¶å™¨
       recordingTimer?.invalidate()
       recordingTimer = nil
       
       // æ ‡è®°å½•åˆ¶å®Œæˆ
       if recordTime >= 1 {
           isRecorded = true
           duration = recordTime
       }
   }
   
   /// å¤„ç†å½•éŸ³æŒ‰é’®ç‚¹å‡»
    private func handleRecordButtonTap() {
        if isRecording {
            stopRecording()
        } else {
            startRecording()
        }
    }
    
    /// é‡æ–°å½•åˆ¶
    private func resetRecording() {
        // åœæ­¢å½“å‰å½•åˆ¶ï¼ˆå¦‚æœæ­£åœ¨å½•åˆ¶ï¼‰
        if isRecording {
            stopRecording()
        }
        
        // åœæ­¢å¹¶æ¸…ç†è®¡æ—¶å™¨
        recordingTimer?.invalidate()
        recordingTimer = nil
        
        // åœæ­¢å¹¶æ¸…ç†æ—§çš„å½•éŸ³å™¨
        if let recorder = audioRecorder {
            if recorder.isRecording {
                recorder.stop()
            }
            audioRecorder = nil
        }
        
        // é‡ç½®éŸ³é¢‘ä¼šè¯ï¼Œç¡®ä¿ä¸‹æ¬¡å½•åˆ¶å¯ä»¥æ­£å¸¸å¼€å§‹
        do {
            // å…³é—­å½“å‰ä¼šè¯å¹¶è®©å…¶ä»–éŸ³é¢‘æ¢å¤
            try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
            // æ˜¾å¼åˆ‡å›å½•éŸ³ç±»åˆ«ï¼Œé˜²æ­¢ä¸Šä¸€è½®è¯•å¬å°†ç±»åˆ«æ”¹ä¸º .playback
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP])
            try audioSession.setActive(true)
        } catch {
            print("é‡ç½®éŸ³é¢‘ä¼šè¯å¤±è´¥: \(error)")
        }
        
        // é‡ç½®æ‰€æœ‰çŠ¶æ€
        isRecorded = false
        recordTime = 0
        duration = 0
        audioURL = ""
        isRecording = false
        isPlaying = false
    }
    //è·å–é¢„ç­¾åURL
    func getPreSignedURL() {
        guard let fileURL = URL(string: audioURL) else {
            MBProgressHUD.showMessag("éŸ³é¢‘è·¯å¾„æ— æ•ˆ", to: nil, afterDelay: 2.0)
            return
        }
        do {
            let data = try Data(contentsOf: fileURL)
            let fileName = fileURL.lastPathComponent.isEmpty ? "audio_\(UUID().uuidString).m4a" : fileURL.lastPathComponent
            let fileSize = data.count
            let fileHash = sha256Hex(of: data)

            let item: [String: Any] = [
                "file_name": fileName,
                "file_size": fileSize,
                "file_hash": fileHash
            ]
            let filesArray = [item]

            guard let jsonData = try? JSONSerialization.data(withJSONObject: filesArray, options: []),
                  let base64String = String(data: jsonData.base64EncodedData(), encoding: .utf8) else {
                MBProgressHUD.showMessag("å‚æ•°ç¼–ç å¤±è´¥", to: nil, afterDelay: 2.0)
                return
            }

            let requestBody: [String: Any] = ["files": base64String]

            NetworkManager.shared.post(APIConstants.Scene.getPresignedUrl,
                                       businessParameters: requestBody) { (result: Result<GetPresignedUrlsResponse, APIError>) in
                Task { @MainActor in
                    switch result {
                    case .success(let response):
                        if response.code == 1 {
                            let item = response.data.first
                            path = item?.path ?? ""
                            print("âœ… é¢„ç­¾åè·å–æˆåŠŸï¼š\(item?.upload_url ?? "")")
                            performAudioUploads(presignedItems:response.data)
                        } else {
                            MBProgressHUD.showMessag(response.msg, to: nil, afterDelay: 2.0)
                        }
                    case .failure(let error):
                        MBProgressHUD.showMessag(error.localizedDescription, to: nil, afterDelay: 2.0)
                    }
                }
            }
        } catch {
            MBProgressHUD.showMessag("è¯»å–éŸ³é¢‘å¤±è´¥ï¼š\(error.localizedDescription)", to: nil, afterDelay: 2.0)
        }
    }
    // è®¡ç®—æ–‡ä»¶ SHA256 å“ˆå¸Œå€¼
    private func sha256Hex(of data: Data) -> String {
        let digest = SHA256.hash(data: data)
        return digest.map { String(format: "%02x", $0) }.joined()
    }
    // ç›´ä¼ éŸ³é¢‘åˆ°é¢„ç­¾åURL
    func performAudioUploads(presignedItems: [PresignedUrlItem]) {
        guard let fileURL = URL(string: audioURL) else {
            print("âŒ éŸ³é¢‘æ–‡ä»¶URLä¸ºç©ºæˆ–æ— æ•ˆ: \(audioURL)")
            return
        }
        do {
            let audioData = try Data(contentsOf: fileURL)
            for item in presignedItems {
                let uploadURLString = item.upload_url
                let fileName = item.file_name
                let previewURL = item.preview_url
                let fileId = item.file_id

                guard let uploadURL = URL(string: uploadURLString) else {
                    print("âŒ æ— æ•ˆçš„ä¸Šä¼ URL: \(uploadURLString)")
                    continue
                }

                var request = URLRequest(url: uploadURL)
                request.httpMethod = "PUT"

                let task = URLSession.shared.uploadTask(with: request, from: audioData) { _, response, error in
                    let statusCode = (response as? HTTPURLResponse)?.statusCode ?? 0
                    let success = (200...299).contains(statusCode)
                    Task { @MainActor in
                        if success {
                            print("âœ… éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: \(fileName)")
                            print("ğŸ”— é¢„è§ˆURL: \(previewURL)")
                            print("ğŸ†” æ–‡ä»¶ID: \(fileId)")
                            // ä½¿ç”¨ SwiftUI çš„ NavigationLink è¿›è¡Œè·³è½¬
                            if !navigateToReleasePanel {
                                navigateToReleasePanel = true
                            }
                            
                        } else {
                            print("âŒ éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ å¤±è´¥: \(fileName), çŠ¶æ€ç : \(statusCode)")
                            if let error = error {
                                print("âŒ é”™è¯¯è¯¦æƒ…: \(error)")
                            }
                        }
                    }
                }
                task.resume()
            }
        } catch {
            print("âŒ è¯»å–éŸ³é¢‘æ–‡ä»¶æ•°æ®å¤±è´¥: \(error)")
        }
    }
}
